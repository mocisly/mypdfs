\newpage

\subsection{Selected Submissions}
\subsubsection{Big List 7 | (Non-)Equivalence of Norms}

The first featured Big List problem is Big List 7. The purpose of this question
was to show that norms are not always equivalent, like how they are for finite
dimensional spaces. I chose to feature this question as I had a lot of trouble
trying to understand on a conceptual level the difference between norms -
functions are quite tricky for me to picture. I also had trouble trying to
really understand the difference between the two spaces, given that the two
norms were simply two different functions defined on the same underlying space;
even now, I still tend to have some difficulty working with norms in certain
scenarios, such as the operator norm.


% q7
\begin{qu}[num=7]
    Let $ S \subseteq C[0, 1] $. Consider the following statements:
    \begin{enumerate}
        \item $ S $ is an open subset of $ (C[0, 1], \norm{\cdot}_{1}) $.
        \item $ S $ is an open subset of $ (C[0, 1], \norm{\cdot}_{\infty}) $.
    \end{enumerate}
    Determine if the first implies the second or vice-versa.
\end{qu}

\begin{soln}
    First, we show that $ (1) \implies (2) $.
    Suppose $ S $ is an open subset of $ (C[0, 1], \norm{\cdot}_{1}) $.
    Let $ f \in S $ be any function.
    Then, we have an open ball $ B_{1}(f, r) $ in the sup norm.
    Let $ g \in B_{1}(f, r) $. Then we have that $ \norm{f - g}_{1} < r $.
    We see that:
    \begin{equation*}
        \norm{f - g}_{1} = \int_{0}^{1} \abs{(f - g)(x)} dx < \int_{0}^{1}
        \abs{r} dx = r
    \end{equation*}
    Therefore, it follows that $ B_{1}(f, r) \subseteq B_{\infty}(f, r) $.
    Since this is true for all $ f $, then we have that $ S $ is open in
    $ (C[0, 1], \norm{\cdot}_{\infty}) $ as needed. \npgh

    Next, we show that $ (2) \cnot\implies (1) $. Note that the sequence
    $ (x_{n})_{n \geq 1} $ given by $ x_{n} = x^{n} $ converges to $ 0 $, since:
    \begin{equation*}
        \int_{0}^{1} x^{n} dx = \frac{1}{n + 1}
    \end{equation*}
    So we can conclude that for all $ \ep > 0 $, there exists some $ N \geq 0 $
    such that
    for all $ n \geq N $, we have that $ \norm{x^{n}}_{1} < \ep $.
    This tells us that we indeed have $ x^{n} \gto 0 $ under the 1-norm. \vsp
    %
    Now, suppose that there exists an open ball $ B_{\infty}(0, r) $ which is
    contained in an open ball $ B_{1}(0, \ep) $. In particular, $ r < \ep $.
    \vsp
    %
    Then, we must have that there exists some $ N_{r} \geq 0 $ such that for all
    $ n \geq N_{r} $,
    we have that $ \norm{x^{n}}_{\infty} < r $. But this is a contradiction,
    since we clearly have that $ \norm{x^{n}}_{\infty} = 1 $, and we can choose
    $ \ep $ to be arbitrarily small.
    Therefore, we cannot inscribe an open ball $ B_{\infty}(0, \ep) $ within
    a ball $ B_{1}(0, \delta) $, so $ (2) \cnot \implies (1) $ as needed.
\end{soln}

\newpage

\subsubsection{Big List 11 | Banach Fixed Point Theorem}

The second featured Big List problem is Big List 11, the Banach Fixed Point
Theorem. This question was particularly notable to me as an exercise in
formalizing intuition and intepretation. While ``picturing" the statement of the
problem was not particularly difficult, conveying the idea in proof form
required a little more effort. It also helped me (alongside the Definition
project) to get accustomed to using sequences of points to prove statements, a
strategy that would be useful for other proofs.

% q11.1
\begin{qu}[title=Banach Fixed Point Theorem,num=11.1]
    Suppose $ (X, d) $ is a complete metric space and $ f : X \gto X $ a
    contraction mapping. Prove that $ f $ has a unique fixed point.
\end{qu}

\begin{soln}
    Let $ x_{0} \in X $ be a point, and define a sequence $ (x_{n})_{n \geq 1} $
    given as:
    \begin{equation*}
        x_{n} = f(x_{n-1})
    \end{equation*}
    Note that for each $ n $-th term:
    \begin{equation*}
        d(x_{n+1}, x_{n}) \leq Md(x_{n}, x_{n-1}) \leq M^{2}d(x_{n-1}, x_{n-2})
        \leq \cdots \leq M^{n}d(x_{1}, x_{0})
    \end{equation*}
    Furthermore, by the triangle inequality, we have:
    \begin{align*}
        d(x_{n+m}, x_{n}) & \leq d(x_{n+m}, x_{n+m-1}) + d(x_{n+m-1}, x_{n}) \\
                          & \leq d(x_{n+m}, x_{n+m-1}) + d(x_{n+m-1}, x_{n+m-2})
                          + d(x_{n+m-2}, x_{n}) \\
                          & \ \: \vdots \\
                          & \leq \sum_{j=n}^{n+m-1} d(x_{j+1}, x_{j}) \\
                          & \leq \sum_{j=n}^{n+m-1} M^{j} d(x_{1}, x_{0}) \\
                          & \leq M^{n}d(x_{1}, x_{0})\sum_{j=0}^{m-1} M^{j} \\
                          & \leq M^{n}d(x_{1}, x_{0})\sum_{j=0}^{\infty}M^{j}
                          \vsp
                          & = \frac{M^{n}d(x_{1}, x_{0})}{1 - M} \vsp
                          & < M^{n}d(x_{1}, x_{0})
    \end{align*}
    Since $ M \in (0, 1) $, then $ \lim_{n \gto \infty} M^{n} = 0 $.
    Therefore as $ m \gto \infty $, we get that $ d(x_{n+m}, x_{n})
    \gto 0 $. Since this holds for any $ n $-th term, then we can conclude
    that the sequence is Cauchy, and therefore $ x_{n} \gto x $ for some
    $ x \in X $. Then, for any $ x_{n} $:
    \begin{equation*}
        d(f(x), x) \leq d(f(x), f(x_{n})) + d(f(x_{n}), x) \leq Md(x, x_{n})
        + d(x_{n+1}, x)
    \end{equation*}
    Since $ x_{n} \gto x $, then $ d(x_{n}, x) \gto 0 $.
    Therefore, we have that:
    \begin{equation*}
        d(f(x), x) = 0 \implies f(x) = x
    \end{equation*}
    So we have that $ x $ is a fixed point of $ f $ as needed.
\end{soln}

\begin{soln}[title=Uniqueness]
    Next, we show that the fixed point is unique.
    For this, suppose $ M \in (0, 1) $ and $ f $ is a contraction mapping. \vsp
    %
    Suppose $ x_{1} $ and $ x_{2} $ are distinct fixed points of $ f $. Then:
    \begin{gather*}
        d(f(x_{1}), f(x_{2})) < d(x_{1}, x_{2}) \qquad
        f(x_{1}) = x_{1} \qquad
        f(x_{2}) = x_{2} \vsp
        \implies \ d(f(x_{1}), f(x_{2})) = d(x_{1}, x_{2}) < d(x_{1}, x_{2})
    \end{gather*}
    Clearly, this is a contradiction, so there cannot be multiple fixed points.
\end{soln}

% q11.2
\begin{qu}[num=11.2]
    Give an example of a normed vector space and a contraction mapping such that
    $ f $ does \textbf{not} have a fixed point.
\end{qu}

\begin{soln}
    Consider $ X = (C[0,1], \norm{\cdot}_{\infty}) $.
    Let $ B = B \left( 0, \frac{1}{2} \right) $, and define:
    \begin{equation*}
        \kappa: B \gto B \qquad \kappa(f) = f^{2} + \frac{1}{4}
    \end{equation*}
    To see that it is a contraction mapping, we first show that the sup norm is
    submultiplicative. Indeed, for all $ x \in [0,1] $, we have that:
    \begin{equation*}
        \abs{f(x)g(x)} = \abs{f(x)}\abs{g(x)} \leq \abs{f(x)}\norm{g} \leq
        \norm{f}\norm{g}
    \end{equation*}
    for some $ f, g \in X $.
    It then follows that $ \norm{fg} \leq \norm{f}\norm{g} $ as needed.
    Now, let $ f, g \in B $ such that $ f \neq g $. Then:
    \begin{align*}
        &  \norm{f^{2}(x) - g^{2}(x)} \\
        = \ & \norm{(f(x) - g(x))(f(x) + g(x))} \\
        \leq \ & \norm{f - g} \norm{f + g} \\
        < \ & \norm{f - g}
    \end{align*}
    Note that the last inequality follows from the fact that $ f, g \in B $.
    Next, to see that it has no fixed points, notice that any fixed point would
    satisfy:
    \begin{equation*}
        f = f^{2} + \frac{1}{4}
        \ \implies \ f^{2} - f + \frac{1}{4} = 0
        \ \implies \ \left( f - \frac{1}{2} \right)^{2} = 0
        \ \implies \ f = \frac{1}{2}
    \end{equation*}
    However, the constant function $ f = \frac{1}{2} \notin B $.
    Therefore, $ \kappa $ is a contraction mapping with no fixed points
    as needed.
\end{soln}

\subsubsection{Big List 18 | Separable Sequence Spaces}

The third featured Big List problem is Big List 18. This question asks whether
or not the space of absolutely summable sequences, $ \ell^{1} $, is separable or
not under two different norms. This was an interesting problem, because I went
into it thinking it would be fairly straightforward, but it turned out to be
surprisingly counterintuitive. In particular, I had thought that the answer to
the first part was ``yes", which made it a more interesting and challenging
question.

% q18.1
\begin{qu}[num=18.1]
    Is $ (\ell^{1},\norm{\cdot}_{\infty}) $ separable?
\end{qu}

\begin{soln}
    No; to show this, we construct an uncountable subset $ S $ of $ \ell^{1} $
    such that for any $ x \neq y \in S $, we have that $ \norm{x-y} = 2 $. To do
    this, define $ S $ as:
    \begin{equation*}
        S \ = \ \set{(x_{n}):x_{n} \in \set{0, 2}}
    \end{equation*}
    This is uncountable by Cantor's Diagonalization argument; alternatively
    since each entry has two options, then there are $ 2^{\bN} =
    \abs{\cl{P}(\bN)} $ possible sequences. Furthermore, for any two sequences
    $ x \neq y \in S $:
    \begin{equation*}
        \norm{x-y} \ = \ \sup\set{\abs{x_{n}-y_{n}}} \ = \ 2
    \end{equation*}
    Thus, we can place a ball of radius 1 around every point in $ S $. Now, if
    there was a countable dense subset $ D $, then there must be some element of
    $ D $ in each ball. However, because there are uncountably many balls, each
    of which are disjoint, this contradicts $ D $ being countable. Thus, we
    conclude that $ (\ell^{1},\norm{\cdot}_{\infty}) $ is not separable as
    needed.
\end{soln}

% q18.2
\begin{qu}[num=18.2]
    Is $ (\ell^{1},\norm{\cdot}_{1}) $ separable?
\end{qu}

\begin{soln}
    Yes. We construct a countable dense subset $ D $ as follows:
    \begin{equation*}
        D \ = \ \set{(x_{n}):x_{n}\in\bQ, x_{n} = 0 \trm{ for all } n \geq m
        \trm{ for some } m}
    \end{equation*}
    To see that this is dense, let $ y \in \ell^{1} $ be any sequence and fix
    $ \ep > 0 $. Note that there must exist some $ M $ such that:
    \begin{equation*}
        \sum_{n=M+1}^{\infty}\abs{y_{n}} < \frac{\ep}{2}
    \end{equation*}
    Furthermore, since $ \bQ $ is dense in $ \bR $, then there exists a sequence
    $ x \in D $ such that for all $ n \leq M $:
    \begin{equation*}
        \abs{x_{n}-y_{n}} < \frac{\ep}{2M}
    \end{equation*}
    Thus, we have that:
    \begin{equation*}
        \norm{x-y} = \sum_{n=1}^{\infty}\abs{x_{n}-y_{n}} \ = \
        \sum_{n=1}^{M}\abs{x_{n}-y_{n}} + \sum_{n=M+1}^{\infty}\abs{y_{n}} \ < \
        \sum_{n=1}^{M}\frac{\ep}{2M} + \frac{\ep}{2} \ = \ \frac{\ep}{2}+
        \frac{\ep}{2} = \ep
    \end{equation*}
    Thus we have that $ D $ is dense in $ (\ell^{1},\norm{\cdot}_{1}) $ as
    needed.
\end{soln}

\newpage
\subsubsection{Big List 19 | Compact Exhaustion}

The fourth featured Big List problem is Big List 19, Compact Exhaustions. I
found this problem to be unexpectedly tricky. Formalizing my ideas for this
question was more difficult, as there were certain key details that needed to be
carefully argued, otherwise they could be incorrect. Getting those details down
was tricky, but after some effort I was able to ultimately come up with an
argument which worked.

% q19.1
\begin{qu}[num=19.1]
    Let $ U \subseteq \bb{R}^{n} $ be a bounded open set. For all $ n \in
    \bb{N} $, define:
    \begin{equation*}
        K_{n} = \set{p \in U : \norm{p - x} \geq \frac{1}{n} \trm{ for all } x
        \in \partial U}
    \end{equation*}
    Show that this is a compact exhaustion of $ U $.
\end{qu}

\begin{soln}
    First, we show that each $ K_{n} $ is compact.
    Clearly each $ K_{n} \subseteq U $, so we show that $ K_{n} $ is closed.
    Consider $ K_{n}^{c} $. We can write it as:
    \begin{align*}
        K_{n}^{c} = \ & U^{c} \cup \set{p \in U: \norm{p - x} <
        \frac{1}{n} \trm{ for some } x \in \partial U} \vsp
        = \ & U^{c} \cup \left( \bigcup_{x \in \partial U}
        B \left( x, \frac{1}{n} \right) \right) \vsp
        = \ & (U^{c} \setminus \partial U) \cup \left( \bigcup_{x \in \p U}
        B \left( x, \frac{1}{n} \right) \right)
    \end{align*}
    Note that we can remove the boundary points of $ U $, as each boundary point
    is contained in one of the open balls in the right-hand union.
    Then, we see that each of these sets are open, and so the entire union is an
    open set. Therefore, $ K_{n}^{c} $ is open, so $ K_{n} $ is closed, and thus
    compact as needed. \vsp
    %
    Next, we show that $ U = \bigcup_{n \geq 1}K_{n} $.
    Indeed, since $ U $ is open, then for any $ x \in U $, there exists some
    $ \ep > 0 $ such that $ B(x, \ep) \subseteq U $. It clearly follows that
    there exists a sufficiently large $ N $ such that:
    \begin{equation*}
        B \left( x, \frac{1}{N} \right) \subseteq B(x, \ep) \subseteq U
    \end{equation*}
    Since $ x \notin \p U $, we can then take sufficiently large $ n \geq N $
    such that:
    \begin{equation*}
        \left( \bigcup_{y \in \p U}B \left( y, \frac{1}{n} \right) \right)\cap B
        \left( x, \frac{1}{n} \right) = \eset
    \end{equation*}
    Thus, we have that $ x \in K_{n} $. \vsp
    %
    Lastly, we show that for all $ n $, we have that $ K_{n} \subseteq
    K_{n+1}^{\circ} $. Suppose $ p_{0} \in K_{n} $ for some fixed $ n $. \vsp
    Let $ \delta = \dfrac{1}{n(n+1)} $. We show that $ B(p_{0}, \delta)\subseteq
    K_{n+1} $. Indeed, let $ p \in B(p_{0}, \delta) $, and fix $ x_{0} \in
    \partial U $ where $ \norm{p - x_{0}} \leq \norm{p - x} $ for all $ x \in
    \partial U $. Then:
    \begin{align*}
        \norm{p_{0} - x_{0}} \leq \ & \norm{p_{0} - p} + \norm{p - x_{0}} \vsp
        \implies \ \norm{p - x_{0}} \geq \ & \norm{p_{0} - x_{0}} - \norm{p_{0}
        - p} \\
        > \ & \frac{1}{n} - \delta \\
        = \ & \frac{1}{n} - \frac{1}{n(n+1)} \\
        = \ & \frac{n}{n(n+1)} \\
        = \ & \frac{1}{n+1}
    \end{align*}
    It follows that $ \norm{p - x} \geq \dfrac{1}{n+1} $ for all $ p \in
    B(p_{0}, \delta) $ and $ x \in \partial U $, so $ B(p_{0}, \delta)
    \subseteq K_{n+1} $ as needed. \vsp
    Since this holds for all $ p_{0} \in K_{n} $, then we have that $ K_{n}
    \subseteq K_{n+1}^{\circ} $ as needed.
\end{soln}

% q19.2
\begin{qu}[num=19.2]
    Now, show that \textit{every} open subset of $ \bb{R}^{n} $ has a compact
    exhaustion.
\end{qu}

\begin{soln}
    Let $ U $ be an open subset of $ \bb{R}^{n} $. Define the set $ U_{n} $ as:
    \begin{equation*}
        U_{n} = U \cap B(0, n)
    \end{equation*}
    Note that for all $ n $, we have that $ U_{n} \subseteq U_{n+1} $.
    Define $ K_{n} $ as follows:
    \begin{equation*}
        K_{n} = \bigcup_{k=1}^{n} K_{k, n}
    \end{equation*}
    where $ K_{k, n} $ is the set defined in part a), replacing $ U $ with
    $ U_{k} $. Clearly, $ K_{n} $ is compact as it is the finite union of
    compact sets. Next, we show that $ U = \bigcup_{n \geq 1} K_{n} $. \vsp
    %
    Let $ x \in U $. Then, fix any $ k \in \bb{N} $ such that $ k > \norm{x} $.
    Then, it follows that:
    \begin{equation*}
        k > \norm{x} \implies x \in U_{k}
    \end{equation*}
    By the same argument in part a), there exists some $ n $ such that $ x \in
    K_{k, n} $, so $ x \in K_{n} $ as needed. \vsp
    %
    Lastly, we show that $ K_{n} \subseteq K_{n+1}^{\circ} $.
    Note that by part a), we have that $ K_{k, n} \subseteq
    K_{k, n+1}^{\circ} $. Recall that:
    \begin{gather*}
        K_{n} = \bigcup_{k=1}^{n} K_{k, n} \vsp
        K_{n+1}^{\circ} = \left( \bigcup_{k=1}^{n+1}K_{k,n+1} \right)^{\circ}
        = \bigcup_{k=1}^{n+1}K_{k,n+1}^{\circ}
    \end{gather*}
    Since $ (A \cup B)^{\circ} = A^{\circ} \cup B^{\circ} $ for any
    $ A, B \subseteq \bb{R}^{n} $, then the result follows.
\end{soln}

\subsubsection{Big List 22 | Isometric Topological Dual}

The fifth featured Big List problem is Big List 22. This question asks to prove
that $ c_{0}^{*} $, the topological dual to the space of sequences convergent to
0, is isometric to $ \ell^{1} $. This question was difficult for me to wrap my
mind around for a long time; I often kept mistaking $ c_{0}^{*} $ with
$ c_{0} $ itself. I also found that constructing the isometry was quite involved
as there were a lot of various criteria to ensure held up for the proof. Overall
I thought it was a rather interesting question, even though functional analysis
isn't really my thing.

% q22
\begin{qu}[num=22]
    Let $ c_{0} $ denote the set of sequences converging to zero.
    Prove that $ c_{0}^{*} \equiv \ell^{1} $.
\end{qu}

\begin{soln}
    We construct an isometry $ f:\ell^{1}\gto c_{0}^{*} $.
    For any $ c \in c_{0} $, we define $ f $ as:
    \begin{equation*}
        f(s) \ = \ \sum_{n=1}^{\infty}s_{n}c_{n} =: g_{s}(c)
    \end{equation*}
    First, we show that $ f(s) \in c_{0}^{*} $. Note that the series converges
    as $ s \in \ell^{1} $ and $ c \in c_{0} $. Linearity follows trivially.
    To see that $ f $ is bounded, notice:
    \begin{equation*}
        \abs{g_{s}(c)} \ = \ \abs{\sum_{n=1}^{\infty}s_{n}c_{n}} \ \leq \
        \sum_{n=1}^{\infty}\abs{s_{n}}\abs{c_{n}} \ \leq \ \sup_{n}(c_{n})
        \sum_{n=1}^{\infty}\abs{s_{n}} \ = \ \norm{s}\norm{c}
    \end{equation*}
    Therefore, we have that:
    \begin{equation*}
        \norm{g_{s}} \ = \ \sup\set{\abs{g_{s}(c)}:c\in c_{0},\norm{c}\leq1}
        \ \leq \ \norm{c}
    \end{equation*}
    It follows that $ f $ is bounded. Next, we show that $ f $ is an isometry.
    Fix $ s \in \ell^{1} $ and $ N \in \bN $. Define a sequence $ c \in c_{0} $
    as follows:
    \begin{equation*}
        c_{n} \ = \
        \begin{cases}
            \frac{s_{n}}{\abs{s_{n}}} & s_{n}\neq0 \trm{ and } n \leq N \\
            0 & s_{n}=0 \trm{ or } n > N
        \end{cases}
    \end{equation*}
    Notice that $ \norm{x} \leq 1 $. Then, as $ N \sto \infty $, we see that:
    \begin{equation*}
        g_{s}(c) \ = \ \sum_{n=1}^{\infty}s_{n}c_{n} \ = \ \sum_{n=1}^{\infty}
        \abs{s_{n}} \ = \ \norm{s}
    \end{equation*}
    Since this is true of any $ s $, we have that $ f $ is an isometry as
    needed. Finally, we show $ f $ is surjective. Indeed, fix $ h \in
    c_{0}^{*} $. Take a basis of $ c_{0} $:
    \begin{equation*}
        \beta \ = \ \set{e_{n}} \qquad
        (e_{n})_{i} \ = \ \delta_{ni}
    \end{equation*}
    In other words, $ \beta $ is the basis of indicator sequences. Then, since
    $ h $ linear, we have:
    \begin{equation*}
        h(c) \ = \ \sum_{n=1}^{\infty}c_{n}h(e_{n})
    \end{equation*}
    Define a sequence $ s \in \ell^{1} $ as $ s_{n} \ = \ h(e_{n}) $.
    Then, for any $ c \in c_{0} $, it follows that:
    \begin{equation*}
        f(s) \ = \ \sum_{n=1}^{\infty}s_{n}c_{n} \ = \ \sum_{n=1}^{\infty}
        h(e_{n})c_{n} \ = \ h(c)
    \end{equation*}
    Note that by our previous work, this also implies that $ s \in \ell^{1} $.
    Thus, we have that $ f $ is a bijective isomorphism, and so we conclude that
    $ c_{0}^{*} \equiv \ell^{1} $ as needed.
\end{soln}

\newpage
\subsubsection{Big List 23 | Stereographic Projection}

The sixth featured Big List problem is Big List 23, Stereographic Projection.
This was a question that I simply enjoyed; I especially felt proud of my
diagrams which I made as visual aids. Of course, I couldn't get too carried away
- I also found that there were certain arguments that needed a little caution
exercised, but nothing too bad. Overall just a fun problem to work on.

% q23.1
\begin{qu}[num=23.1]
    Find an explicit formula for $ \Phi : S^{2} \setminus \set{(0, 0, 1)} \gto
    \bb{R}^{2} $, given as the stereographic projection of the unit $ 2 $-sphere
    onto $ \bb{R}^{2} $.
\end{qu}

\begin{soln}
    First, consider the problem reduced by one dimension.
    We want to find $ \Phi(P) $ satisfying:

    \centering
    \scalebox{.95}{\incfig{stereoproject2d}}
    \flushleft

    Here, we can use properties of similar triangles to derive that
    $ \dfrac{\Phi(P)}{1} = \dfrac{x}{1-y} $.
    To extend this up a dimension to our original problem, we see that:
    
    \centering
    \scalebox{.75}{\incfig{stereoproject3d}} \\
    \small Still unsure how these diagrams are getting to school... Bad joke?
    \flushleft
    
    \normalsize
    In other words, we can project the point $ P $ onto the $ xz $-plane and
    $ yz $-plane, then projecting those points onto the $ xy $-plane in order to
    get the $ x $-component and $ y $-component respectively of $ \Phi(P) $. As
    a formula, we get:
    \begin{equation*}
        \Phi(x, y, z) = \left( \frac{x}{1-z}, \frac{y}{1-z} \right)
    \end{equation*}
\end{soln}

% q23.2
\begin{qu}[num=23.2]
    Deduce that $ \Phi $ is continuous.
\end{qu}

\begin{soln}
    We can write $ \Phi $ as:
    \begin{equation*}
        \Phi(x, y, z) = (\Phi_{1}(x,y,z), \Phi_{2}(x,y,z))
    \end{equation*}
    Then, since each $ \Phi_{i} $ is clearly continuous, it follows that
    $ \Phi $ is continuous as well.
\end{soln}

% q23.3
\begin{qu}[num=23.3]
    Given $ p = (s, t) \in \bb{R}^{2} $, find an explicit formula for
    $ \Phi^{-1}(p) $.
\end{qu}

\begin{soln}
    We want to solve for $ x, y, $ and $ z $ such that:
    \begin{equation*}
        s = \frac{x}{1-z} \qquad t = \frac{y}{1-z} \qquad x^{2}+y^{2}+z^{2}=1
    \end{equation*}
    First, notice we that $ x = (1-z)s, y = (1-z)t $.
    Then, rearranging the equation of the unit sphere, we get that:
    \begin{align*}
        & x^{2} + y^{2} = 1 - z^{2} \\
        \implies \ & x^{2} + y^{2} = (1-z)(1+z) \\
        \implies \ & (1-z)^{2}s^{2} + (1-z)^{2}t^{2} = (1-z)(1+z) \\
        \implies \ & s^{2} + t^{2} = \frac{1+z}{1-z}
    \end{align*}
    Denoting $ N = s^{2} + t^{2} $, and rearranging, we get that:
    \begin{equation*}
        1 + z = N(1 - z) \ \implies \ z = \frac{N - 1}{N + 1}
    \end{equation*}
    Finally, substituting this value of $ z $ into our other equations, we have:
    This gives us the final formula for the inverse as:
    \begin{equation*}
        \Phi^{-1}(s, t) = \left( \frac{2s}{s^{2} + t^{2} + 1},
        \frac{2t}{s^{2}+t^{2}+1},\frac{s^{2}+t^{2}-1}{s^{2}+t^{2}+1}
        \right)
    \end{equation*}
\end{soln}

% q23.4
\newpage
\begin{qu}[num=23.4]
    Deduce that $ \Phi $ is a homeomorphism.
\end{qu}

\begin{soln}
    Similarly to above, we can see that each component of $ \Phi^{-1} $ is
    continuous, and thus $ \Phi^{-1} $ is continuous. \vsp
    %
    Since $ \Phi $ and $ \Phi^{-1} $ are both continuous, then $ \Phi $ is
    indeed a homeomorphism.
\end{soln}

\newpage

\subsubsection{Big List 27 | Feynman's Trick}

The seventh featured Big List problem is Big List 27, Feynman's Trick. This
problem was also difficult for me, but for a different reason - the trick itself
feels so simple, but it's easy to overlook details and get something wrong. The
difficulty came in making sure that every detail was covered, while also keeping
the proof relatively straightforward and not excessively overcomplicating the
argument.

% q27.1
\begin{qu}[num=27.1]
    Let $ f : \bb{R}^{2} \gto \bb{R} $ be continuously differentiable.
    Show that the map $ \bb{R} \gto \bb{R} $ given by $ t \mto f(x, t) $ is
    integrable.
\end{qu}

\begin{soln}
    Since $ f $ is continuous, the map is also continuous and thus integrable.
\end{soln}

% q27.2
\begin{qu}[title=Feynman's Trick,num=27.2]
    Define the map $ \vphi: \bb{R}\gto \bb{R} $ by:
    \begin{equation*}
        \vphi(x) = \int_{a}^{b} f(x,t) \di t
    \end{equation*}
    Show that $ \vphi $ is differentiable, with derivative given by:
    \begin{equation*}
        \frac{\d\!\vphi}{\d x}(x_{0}) = \int_{a}^{b}\frac{\p f}{\p x} (x_{0}, t)
        \di t
    \end{equation*}
    This is known as differentiation under the integral sign, or sometimes
    Feynman's trick.
\end{qu}

\begin{soln}
    By definition, we have that:
    \begin{equation*}
        \frac{\d\!\vphi}{\d x} = \lim_{h\gto0}\frac{\int_{a}^{b}f(x+h,t)\di t
        - \int_{a}^{b}f(x,t)\di t}{h} \ = \
        \lim_{h\gto0} \frac{\int_{a}^{b}f(x+h,t)-f(x,t)\di t}{h}
    \end{equation*}
    This limit exists by FTC. Then, notice that:
    \begin{align*}
        \abs{\frac{\d\!\vphi}{\d x} - \int_{a}^{b}\frac{\p f}{\p x}(x, t)\di t}
        \ & = \ \abs{\frac{\int_{a}^{b}f(x+h,t)-f(x,t)\di t}{h} - \int_{a}^{b}
            \p_{x} f(x,t)\di t} \vsp
        & = \ \abs{\int_{a}^{b}\frac{f(x+h,t)-f(x,t)-h\p_{x}f(x,t)}{h}\di t}
        \vsp
        & \leq \ \int_{a}^{b}\abs{\frac{f(x+h,t)-f(x,t)}{h} - \p_{x}f(x,t)}
        \di t
    \end{align*}
    As $ h \gto 0 $, we have that the term in the absolute value is less than
    $ \ep $ for any $ \ep > 0 $, by definition of partial derivative. Therefore,
    we conclude that the two values are equal as needed.
\end{soln}

% q27.3
\newpage
\begin{qu}[num=27.3]
    Use Feynman's trick to solve the single-variable integral:
    \begin{equation*}
        \int_{0}^{\infty} e^{-t^{2}} \di t
    \end{equation*}
\end{qu}

\begin{soln}
    We want to solve for $ I $, where $ I $ is the definite integral given by:
    \begin{equation*}
        I = \int_{0}^{\infty}e^{-t^{2}}\di t
    \end{equation*}
    By the hint, consider the function $ f:\bb{R}^{2}\gto\bb{R} $ given by:
    \begin{equation*}
        f(x,t) = \frac{e^{-x^{2}(1+t^{2})}}{1+t^{2}}
    \end{equation*}
    Note that as $ x \gto \infty $, $ f(x) \gto 0 $.
    Define the function $ \vphi:\bb{R}\gto\bb{R} $ as:
    \begin{equation*}
        \vphi(x) = \int_{0}^{\infty}f(x,t)\di t
    \end{equation*}
    Using Feynman's trick, we see that:
    \begin{align*}
        \frac{\d\!\vphi}{\d x} \ & = \ \int_{0}^{\infty} \frac{\p}{\p x}
        \frac{e^{-x^{2}(1+t^{2})}} {1+t^{2}} \di t \vsp
        & = \ \int_{0}^{\infty}\frac{-2x(1+t^{2})e^{-x^{2}(1+t^{2})}}{1+t^{2}}
        \di t \vsp
        & = \ -2e^{-x^{2}}\int_{0}^{\infty} xe^{-x^{2}t^{2}} \di t \vsp
        & = \ -2e^{-x^{2}}\int_{0}^{\infty}e^{-u^{2}}\di u \vsp
        & = \ -2e^{-x^{2}}I
    \end{align*}
    where we do a $ u $-substitution with $ u = xt $.
    Integrating back, we see that:
    \begin{gather*}
        \int_{0}^{\infty} \frac{\d\!\vphi}{\d x}\di x \ = \ \int_{0}^{\infty}
        -2e^{-x^{2}}I\di x \ \implies \ I^{2} \ = \ \frac{\vphi(0)}{2} \vsp
        \vphi(0) \ = \ \int_{0}^{\infty}f(0,t)\di t \ = \ \int_{0}^{\infty}
        \frac{1}{1+t^{2}} \di t \ = \ \arctan(x) \ \Big|_{0}^{\infty} \ = \
        \frac{\pi}{2}
    \end{gather*}
    Therefore, we have that:
    \begin{equation*}
        I^{2} \ = \ \frac{\pi}{4} \ \implies \ I \ = \ \frac{\sqrt{\pi}}{2}
    \end{equation*}
\end{soln}

\newpage
\subsubsection{Big List 4, 30 | Bump Functions}

The eighth featured Big List problem(s) are actually two problems, Big List 4
and Big List 30. These are the questions regarding the construction of bump
functions. These questions stand out for their narrative element; a seemingly
innocuous question at the start of the year creeping back midway through only to
turn out to be vital for the construction of partitions of unity. Narrative
aside, I also found question 4 to be quite technical (at least, when I
originally solved it). Back then, such a proof felt quite hefty and like a lot
of work. Technically, it's still the same amount of work, but it doesn't seem
all that bad now. Looking back, I get a sense of how much work we've done
altogether throughout the entire year.

% q4.1
\begin{qu}[num=4.1]
    Prove that there exists an infinitely differentiable function
    $ \alpha: \bb{R} \gto \bb{R} $ such that $ \alpha(t) = 0 $ for all
    $ t \leq 0 $, and $ \alpha(t) > 0 $ for all $ t > 0 $.
\end{qu}

\begin{soln}
    We define a function, and prove it is infinitely differentiable on all
    $ \bb{R} $. Consider the function
    \begin{equation*}
        \alpha(t) = \begin{cases} 0 & t \leq 0 \\ e^{-1/t} & t > 0 \end{cases}
    \end{equation*}
    Clearly, $ \alpha $ is infinitely differentiable for $ t < 0 $.
    We show the cases $ t > 0 $ and $ t = 0 $ separately. \npgh

    Suppose $ t > 0 $. We will show by induction that $ \alpha^{(n)}(t) $ is of
    the form
    \begin{equation*}
        \alpha^{(n)}(t) = \frac{d^{n}}{dt^{n}} e^{-1/t} = e^{-1/x} P_{2n}
        \left( \frac{1}{t} \right)
    \end{equation*}
    where $ \alpha^{(n)}(t) $ is the $ n $-th derivative of $ \alpha $ at $ t $,
    and $ P_{2n}(\frac{1}{t}) $ is a polynomial of degree $ 2n $ over the
    variable $ 1/t $. \vsp
    %
    Base case: Let $ n = 1 $.
    Then, $ a^{(1)}(t) = \dfrac{d}{dt} e^{-1/t} $ is given by:
    \begin{equation*}
        \frac{d}{dt} e^{-1/t} = \frac{e^{-1/t}}{t^{2}} = e^{-1/t}
        \left( \frac{1}{t} \right)^{2}
    \end{equation*}
    Induction step: Suppose our claim is true for some $ n = k $.
    We show that it holds for $ n = k +1 $.
    For the sake of readability, denote $ y = 1/t $. Indeed, we see that:
    \begin{align*}
        \frac{d^{k+1}}{dt^{k+1}} \alpha(t) = & \frac{d}{dt} \alpha^{(k)}(t) \\
                    = & \frac{d}{dt} e^{-y}P_{2k}(y) \\
                    = & \frac{d}{dt} e^{-y}\sum_{i = 0}^{2k} {a_{i}y^{i}} \\
                    = & y^{2} e^{-y} \sum_{i=0}^{2k} {a_{i}y^{i}}
                    + e^{-y} \sum_{i = 0}^{2k-1} {(i+1)a_{i+1}y^{i}} \\
                    = & e^{-y} \left( \sum_{i=0}^{2k} {a_{i}y^{i+2}}
                    + \sum_{i=0}^{2k-1} {(i+1)a_{i+1}y^{i+2}} \right) \\
                    = & e^{-y} \left( P_{2k+2}(y) + P_{2k+1}(y) \right) \\
                    = & e^{-1/t} P_{2(k+1)} \left( \frac{1}{t} \right)
    \end{align*}
    Therefore, by induction, our claim is proven.
    Since we know what the $ n $-th derivative looks like for $ \alpha(t) $ with
    $ t > 0 $ for any arbitary $ n \in \bb{N} $, we can conclude that
    $ \alpha(t) $ is infinitely differentiable on all $ t > 0 $ as needed. \npgh
    
    It remains to show that $ \alpha(t) $ is infinitely differentiable at
    $ t = 0 $. To do this, we will again proceed by induction, with the claim
    that the $ n $-th derivative of $ \alpha(0) = 0 $. \vsp
    %
    Base case: Let $ n = 1 $. Then, we have that
    \begin{align*}
        \frac{d}{dt} \alpha(0) & = \lim_{h\gto 0} \frac{\alpha(0 + h)
        - \alpha(0)}{h} \\
                               & = \lim_{h \gto 0} \frac{\alpha(h)}{h}
    \end{align*}
    We examine each side of the limit.
    Clearly, the left-sided limit is equal to 0, so we 
    denote $ y = 1/h $ and examine the right-sided limit. We see that:
    \begin{align*}
        & \lim_{ h \gto 0^{+}} \frac{e^{-1/h}}{h} \\
        = \ & \lim_{y \gto \infty} \frac{y}{e^{y}} \\
        = \ & \lim_{y \gto \infty} \frac{1}{e^{y}} \\
        = \ & 0
    \end{align*}
    Where we use L'Hopital's Rule in the third line.
    Then, since the left and right-sided limits are equal,
    the original limit must exist and be equal to 0.
    Therefore, $ \alpha'(0) = 0 $ as needed. \vsp
    %
    Induction step: Suppose $ \alpha^{(k)}(0) = 0 $.
    We show that $ \alpha^{(k+1)}(0) = 0 $. Indeed:
    \begin{align*}
        \frac{d^{n}}{dt^{n}} \alpha(0) & = \lim_{h \gto 0} 
        \frac{\alpha^{(k)}(h + 0) - \alpha^{(k)}(0)}{h} \\
                    & = \lim_{h \gto 0} \frac{\alpha^{(k)}(h)}{h}
    \end{align*}
    Once again, we examine the sided limits, letting $ y = 1/h $ as needed.
    Again, the left-sided limit is trivially 0. Examining the right-sided limit,
    we see that:
    \begin{align*}
        & \lim_{h \gto 0^{+}} \frac{a^{(k)}(h)}{h} \\
        = \ & \lim_{h \gto 0^{+}} \frac{e^{-y}P_{2k}(y)}{h} \\
        = \ & \lim_{y \gto \infty} \frac{P_{2k+1}(y)}{e^{y}} \\
        = \ & \lim_{y \gto \infty} \frac{P_{2k}(y)}{e^{y}} \\
            & \vdots \\
        = \ & \lim_{y \gto \infty} \frac{cy}{e^{y}} \\
        = \ & \lim_{y \gto \infty} \frac{c}{e^{y}} \\
        = \ & 0
    \end{align*}
    where $ c $ is some constant, and we apply L'Hopital's Rule $ 2k + 1 $
    times. Since each sided limit is equal to 0, then the original limit must
    equal 0, which means that $ \alpha^{(k+1)}(0) = 0 $ as needed. \npgh

    We have now shown that $ \dfrac{d^{n}}{dt^{n}} \alpha(t) $ exists for all
    $ t \in \bb{R} $, so $ \alpha $ is infinitely differentiable as needed.
\end{soln}

% q4.2
\begin{qu}[num=4.2]
    Prove that there exists an infinitely differentiable function
    $ \beta: \bb{R} \gto \bb{R} $ such that $ \beta(t) = 1 $ for all
    $ t \geq 1 $, and $ \beta(t) = 0 $ for all $ t \leq 0 $.
\end{qu}

\begin{soln}
    Consider the function defined by:
    \begin{equation*}
        \beta(t) = \frac{\alpha(t)}{\alpha(t) + \alpha(1-t)}
    \end{equation*}
    where $ \alpha(t) $ is the function defined in part 1. \vsp
    %
    It is easy to see that $ \beta(t) $ is infinitely differentiable,
    since $ \beta(t) $ consists of copies of $ \alpha(t) $ along with basic
    operations which preserve the infinite differentiability. \vsp
    %
    Clearly, if $ t \geq 1 $, then $ \alpha(1 - t) = 0 $. Thus, for any
    $ t \geq 1 $, we see that
    \begin{equation*}
        \beta(t) = \frac{\alpha(t)}{\alpha(t)} = 1
    \end{equation*}
    Similarly, if $ t \leq 0 $, then $ \alpha(1 - t) > 0 $, so:
    \begin{equation*}
        \beta(t) = \frac{0}{\alpha(1 - t)} = 0
    \end{equation*}
\end{soln}

% q4.3
\begin{qu}[num=4.3]
    Prove that there exists an infinitely differentiable function
    $ \vphi: \bb{R} \gto \bb{R} $ such that $ \vphi(t) = 1 $ for all
    $ t \in [2, 3] $, and $ \vphi(t) = 0 $ for all $ t \in \bb{R} \setminus
    (1, 4) $.
\end{qu}

\begin{soln}
    Consider the function given by:
    \begin{equation*}
        \vphi(t) = \beta(t - 1)\beta(4 - t)
    \end{equation*}
    Clearly, $ \vphi $ is infinitely differentiable. \vsp
    %
    Consider $ t \leq 1 $. Then, $ \beta(t - 1) = 0 $, so $ \vphi(t) = 0 $.
    Similarly, if $ t \geq 4 $, then $ \beta(4 - t) = 0 $, so $ \vphi(t) = 0 $.
    \vsp
    %
    Now, suppose $ t \in [2, 3] $.
    Then, $ t - 1 \in [1, 2] \geq 0 $ and $ 4 - t \in [1, 2] \geq 0 $.
    So, we see that $ \vphi(t) = 1 $ as needed.
\end{soln}

% q30
\newpage
\begin{qu}[num=30]
    Let $ U \subseteq \bR^{n} $ be open, and $ K \subseteq U $ compact.
    Prove that there exists an infinitely differentiable function $ \vphi:
    \bR^{n} \gto [0, 1] $ such that $ \vphi(p) = 1 $ for all $ p \in K $, and
    $ \vphi(p) = 0 $ for all $ p \in \bR^{n} \setminus U $. This is called a
    \textbf{bump function} supported on $ U $.
\end{qu}

\begin{soln}
    First, suppose $ K, U $ are closed/open rectangles respectively. Then, we
    can write:
    \begin{equation*}
        K = \prod_{i=1}^{n}[a_{i},b_{i}] \qquad
        U = \prod_{i=1}^{n}(c_{i},d_{i})
    \end{equation*}
    By Big List 4, we know there exist bump functions $ \vphi_{i}:\bR\gto[0,1] $
    such that $ \vphi_{i}(p_{i})=1 $ for all $ p \in [a_{i},b_{i}] $ and
    $ \vphi_{i}(p_{i})=0 $ for all $ p \in \bR\setminus(c_{i},d_{i}) $. Thus,
    we can define our function:
    \begin{equation*}
        \vphi(p) \ = \ \prod_{i=1}^{n}\vphi_{i}(p_{i})
    \end{equation*}
    Indeed, when $ p \in K $, each $ p_{i} \in [a_{i},b_{i}] $, and so we have
    $ \vphi_{i}(p_{i})=1 $. Similarly, if $ p \in \bR^{n}\setminus U $, then
    $ p_{i} \in \bR\setminus(c_{i},d_{i}) $ for some $ i $, and thus $ \vphi_{i}
    (p_{i})=0 $ as needed. \vsp
    %
    Next, suppose $ K $ is a finite union of rectangles; WLOG, write
    $ K = K_{1} \cup K_{2} $, where each $ K_{i} $ is a rectangle. Then, there
    are bump functions $ \alpha, \beta $ on $ K_{1}, K_{2} $ respectively. We
    define:
    \begin{equation*}
        \vphi(p) \ = \ \alpha(p) + \beta(p) - \alpha(p)\beta(p)
    \end{equation*}
    Here, we mimic the principle of inclusion/exclusion. Clearly, $ \vphi $ is
    smooth; for any $ p \in K_{1} $ or $ K_{2} $, we respectively have that:
    \begin{equation*}
        \vphi(p) \ = \ 1 + \beta(p) - \beta(p) \qquad
        \vphi(p) \ = \ \alpha(p) + 1 - \alpha(p)
    \end{equation*}
    So clearly $ \vphi(p) = 1 $ on $ K $. It is also easy to see that it is 0
    outside of $ U $ as needed. \vsp
    %
    Finally, consider any arbitrary $ K $. Since $ U $ is open, then it has a
    compact exhaustion $ \set{K_{i}} $. Then, there must exist some $ m-1 $
    such that $ K \subseteq K_{m-1} $. Otherwise, we would have that $ K $ is
    not a subset of any $ K_{i} $ for all $ i $, and since $ \bigcup_{i}K_{i}
    = U $, then $ K $ could not be a subset of $ U $. Thus, we have $ K_{m} $
    compact where $ K \subseteq K_{m}^{\circ} \subseteq K_{m} \subseteq U $.
    \vsp
    %
    Now, let $ \set{C_{\alpha}} $ be a cover of rectangles of $ K_{m} $, with
    each $ C_{\alpha} \subsetneq U $. Since $ K_{m} $ compact, there exists a
    finite subcover $ \set{C_{r}}_{r=1}^{s} $. Since each $ C_{r} \subsetneq
    U $, we can define $ \vphi $ analogously to the finite union case above to
    obtain our bump function as needed.
\end{soln}

\newpage
\subsubsection{Big List 37 | Measure of the Simplex}

The ninth featured Big List problem is Big List 37, the measure of the
$ n $-simplex. I found this question to be quite fun more than anything, and
served as a good test of my computational skills, which I had been worrying was
perhaps rusting a bit too much. Solving a large iterated integral also took some
notable effort, but I felt very satisfied after figuring out a pattern and
coming up with what I felt was a clean solution.

% q37
\begin{qu}[title=A Mathematician's Dream,num=37]
    The following is called the $ n $-simplex:
    \begin{equation*}
        \Delta_{n} :=
        \set{x = (x_{1}, \dots, x_{n}) \in \bR^{n}:
        x_{1}, \dots, x_{n} \geq 0 \trm{ and } x_{1} + \dots + x_{n} \leq 1}
    \end{equation*}
    Find, with proof, an explicit formula for $ \mu(\Delta_{n}) $ in terms of
    $ n $.
\end{qu}

\begin{soln}
    Note that we can model the first few simplexes as:
    \begin{gather*}
        \Delta_{1} = [0, 1] \qquad
        \Delta_{2} = \set{(x, 1-x) \in \bR^{2} : x \in [0, 1]} \\
        \Delta_{3} = \set{(x, y, 1-x-y) \in \bR^{3} : x \in [0, 1], y \in
        [0, 1-x]}
    \end{gather*}
    Thus, we can use the integral form of measure and integrate over these sets:
    \begin{gather*}
        \mu(\Delta_{n}) \ = \ \int_{\Delta_{n}}1 \vsp
        \mu(\Delta_{1}) \ = \ \int_{0}^{1}1\ \d x \qquad
        \mu(\Delta_{2}) \ = \ \int_{0}^{1}\int_{0}^{1-x}1\ \d y\d x \vsp
        \mu(\Delta_{3}) \ = \ \int_{0}^{1}\int_{0}^{1-x}\int_{0}^{1-x-y}
        1\ \d z\d y\d x
    \end{gather*}
    We can generalize this to $ \bR^{n} $:
    \begin{equation*}
        \mu(\Delta_{n}) \ = \ \underbrace{
            \int_{0}^{1}\int_{0}^{1-x_{1}}\cdots
            \int_{0}^{1-\sum_{i=1}^{n-1}x_{i}}
        }_{n \trm{ integrals}} 1\ \d x_{n}\d x_{n-1}\cdots \d x_{1}
    \end{equation*}
    To find a closed-form expression, we can evaluate the integral.
    To do this, we define an auxiliarry variable:
    \begin{equation*}
        c_{0} = 1 \qquad c_{k} = 1 - \sum_{i=1}^{n-k}x_{i}
    \end{equation*}
    We emphasize that:
    \begin{gather*}
        c_{k} = c_{k+1}-x_{n-k} \vsp
        \int_{0}^{1}\cdots
        \int_{0}^{1-\sum_{i=1}^{n-1}x_{i}}
        1\ \d x_{n}\cdots \d x_{1} \ = \
        \int_{0}^{c_{n}}\cdots
        \int_{0}^{c_{1}}
        c_{0}\ \d x_{n}\cdots \d x_{1}
    \end{gather*}
    Finally, to prove the closed form, we claim that:
    \begin{equation*}
        \int_{0}^{c_{k+1}}c_{k}^{k}\ \d x_{n-k} \ = \
        \frac{1}{k+1}c_{k+1}^{k+1}
    \end{equation*}
    Indeed, we see that:
    \begin{align*}
        \int_{0}^{c_{k+1}}c_{k}^{k}\ \d x_{n-k}
        & \ = \ \int_{0}^{c_{k+1}}(c_{k+1}-x_{n-k})^{k}\ \d x_{n-k} \vsp
        & \ = \ \int_{0}^{c_{k+1}}\sum_{i=0}^{k}\binom k i c_{k+1}^{k-i}
        (-x)_{n-k}^{i}\ \d x_{n-k} \vsp
        & \ = \ \sum_{i=0}^{k}\frac{(-1)^{i}}{i+1}\binom k ic_{k+1}^{k-i}
        x_{n-k}^{i+1}\bigg\rvert_{0}^{c_{k+1}} \vsp
        & \ = \ c_{k+1}^{k+1}\sum_{i=0}^{k}\frac{(-1)^{i}}{i+1}\binom k i \vsp
        & \ = \ c_{k+1}^{k+1}\sum_{i=0}^{k}(-1)^{i}\binom k i \int_{0}^{1}x^{i}\
        \d x \vsp
        & \ = \ c_{k+1}^{k+1}\int_{0}^{1}\sum_{i=0}^{k}(-1)^{i}\binom k ix^{i}\
        \d x \vsp
        & \ = \ c_{k+1}^{k+1}\int_{0}^{1}(1-x)^{k}\ \d x \vsp
        & \ = \ c_{k+1}^{k+1}\int_{0}^{1}u^{k}\ \d k \vsp
        & \ = \ c_{k+1}^{k+1}\frac{1}{k+1}
    \end{align*}
    Thus, evaluating the integral, we get:
    \begin{align*}
        \int_{0}^{c_{n}}\cdots \int_{0}^{c_{1}}
        c_{0}\ \d x_{n}\cdots \d x_{1} & \ = \ \frac{1}{1}
        \int_{0}^{c_{n}}\cdots \int_{0}^{c_{2}}
        c_{1}\ \d x_{n-1}\cdots \d x_{1} \vsp
        & \ = \ \frac{1}{2} \int_{0}^{c_{n}}\cdots \int_{0}^{c_{3}}
        c_{2}^{2}\ \d x_{n-2}\cdots \d x_{1} \vsp
        & \ = \ \frac{1}{2\cdot3} \int_{0}^{c_{n}}\cdots \int_{0}^{c_{4}}
        c_{3}^{3}\ \d x_{n-3}\cdots \d x_{1} \\
        & \ \ \ \vdots \\
        & \ = \ \frac{1}{n!}
    \end{align*}
    So we conclude that $ \mu(\Delta_{n}) = \dfrac{1}{n!} $ as needed.
\end{soln}

\newpage
\subsubsection{Big List 41 | The Tasty Torus}

The tenth and final featured Big List problem is Big List 41. This was an
interesting problem about defining the torus in $ \bR^{3} $ and finding its
surface area. I felt this question really tested how comfortable I am with
geometry, since I consider that to be one of my weaker senses in math as a
whole. Similar to 37, it also gave a calculation which I thought had quite the
neat solution, and was fun, albeit tricky, to come up with the parametrization
and subsequent calculation.

% q41.1
\begin{qu}[num=41.1]
    Let $ 0 < a < b $. Find a smooth function $ f:U \gto \bR $ for some open
    $ U \subseteq \bR^{3} $, so that the torus $ T = T_{a,b} $ is the zero set
    of $ f $.
\end{qu}

\vspace{-0.3in}
\begin{soln}
    Consider a point $ (x,y,z) $ on $ T $. Then, it must be on a circle of
    radius $ a $ centered at the nearest point of the circle of radius $ b $ on
    the $ xy $-plane, centered at the origin. Since every point on the circle of
    radius $ b $ necessarily has a norm of $ b $, denote:
    \begin{equation*}
        d \ = \ \norm{\pi_{2}(p)} - b \ = \ \sqrt{x^{2}+y^{2}}-b
    \end{equation*}
    This represents the point's (horizontal) distance from the circle of radius
    $ b $. In particular, this represents a line segment between the point and
    the circle of radius $ b $ which is parallel to the normal vector of the
    circle at that point. Since we want our point $ p $ to be on a circle of
    radius $ a $ from here, then:
    \begin{equation*}
        d^{2}+z^{2}=a^{2}
    \end{equation*}
    Because $ d $ represents a line segment parallel to a normal vector, this
    in fact gives us a circle rather than a sphere. In particular, this circle
    shifts as $ x,y $ change; thus, we never get a full sphere. Substituting
    $ d $ back gives us:
    \begin{equation*}
        (\sqrt{x^{2}+y^{2}}-b)^{2}+z^{2}=a^{2} \ \implies \
        f(x,y,z) = (\sqrt{x^{2}+y^{2}}-b)^{2}+z^{2}-a^{2}
    \end{equation*}
    So $ T $ is given as the zero set of $ f $ defined above.
\end{soln}

% q41.2
\newpage
\begin{qu}[num=41.2]
    Show that $ T $ is a smooth manifold.
\end{qu}

\begin{soln}
    It remains to show that $ \nabla f \neq 0 $ for all $ p $. Indeed:
    \begin{equation*}
        \frac{\p f}{\p x} \ = \
        2(\sqrt{x^{2}+y^{2}}-b)\left( \frac{x}{\sqrt{x^{2}+y^{2}}} \right) \ = \
        2x \left( 1-\frac{b}{\sqrt{x^{2}+y^{2}}} \right)
    \end{equation*}
    Analogously:
    \begin{equation*}
        \frac{\p f}{\p y} \ = \
        2(\sqrt{x^{2}+y^{2}}-b)\left( \frac{y}{\sqrt{x^{2}+y^{2}}} \right) \ = \
        2y \left( 1-\frac{b}{\sqrt{x^{2}+y^{2}}} \right)
    \end{equation*}
    We clearly see that $ \frac{\p f}{\p z} = 2z $. Thus, $ \nabla f $ is only 0
    at $ 0 \in \bR^{3} $; thus, we can simply exclude it from our domain. Thus,
    considering $ f\rvert_{\bR^{3}\setminus\set{0}} $, we see that $ T $ is
    indeed a manifold as needed.
\end{soln}

% q41.3
\begin{qu}[num=41.3]
    Find the surface area of $ T $, in terms of $ a $ and $ b $.
\end{qu}

\begin{soln}
    We parametrize using angles; let $ \theta $ denote the angle with respect to
    the main circle (with radius $ b $), and let $ \rho $ denote the angle with
    respect to the inner circle (with radius $ a $). First, note that $ z $ does
    not change when $ \rho $ is fixed, so $ z = \sin\rho $. \vsp
    %
    Then, notice that the $ x, y $ coordinates change slightly by $ a $
    depending on the ``$ d $" coordinate we defined earlier, and is given by
    $ \cos\rho $. This shifts $ x,y $ by a value up to $ a $, and so we have a
    parametrization:
    \begin{equation*}
        f(\theta,\rho) \ = \ ((b+a\cos\rho)\cos\theta, (b+a\cos\rho)\sin\theta,
        \sin\rho)
    \end{equation*}
    Calculating $ V(Jf) $ gives us $ V(Jf) = a(b+a\cos\rho) $, and so the
    surface area is:
    \begin{equation*}
        \int_{0}^{2\pi}\int_{0}^{2\pi}ab+a^{2}\cos\rho\di\rho\di\theta \ = \
        2\pi a \left( \int_{0}^{2\pi}b+a\cos\rho\di\rho \right) \ = \
        4\pi^{2}ab
    \end{equation*}
    So the surface area of a torus $ T_{a,b} $ is given as $ 4\pi^{2}ab $.
\end{soln}

